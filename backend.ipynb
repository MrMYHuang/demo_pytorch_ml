{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f133851-7253-4a8c-9845-83e98f5a2ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "from typing import Optional\n",
    "\n",
    "from contextlib import asynccontextmanager\n",
    "from fastapi import FastAPI, WebSocket, HTTPException\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from safetensors.torch import load_file\n",
    "from LinearRegression import *\n",
    "import torch\n",
    "device = 'mps' if torch.backends.mps.is_available() else 'cuda' if torch.backends.cuda.is_available() else 'cpu'\n",
    "torch.set_default_device(device)\n",
    "\n",
    "model: LinearRegression = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805d8755-6372-4e84-a267-953bcbebe976",
   "metadata": {},
   "outputs": [],
   "source": [
    "@asynccontextmanager\n",
    "async def lifespan(app: FastAPI):\n",
    "    global init_models_thread\n",
    "    init_models_thread.start()\n",
    "    yield\n",
    "\n",
    "app = FastAPI(title=__name__, lifespan=lifespan)\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],          # Allowed origins\n",
    "    allow_credentials=True,         # Allow cookies/auth headers\n",
    "    allow_methods=[\"*\"],            # Allow all HTTP methods\n",
    "    allow_headers=[\"*\"],            # Allow all HTTP headers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3f2f81-e72e-4bc9-bb71-5a549ea507f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predict(BaseModel):\n",
    "    x: int\n",
    "\n",
    "@app.post(\"/predict\")\n",
    "async def predict(\n",
    "    p: Predict,\n",
    "):\n",
    "    global model\n",
    "    if model is None:\n",
    "        raise HTTPException(\n",
    "            status_code=400,\n",
    "            detail=[{\"msg\": \"Models are not ready. Check the backend log for keyword 'init_models done.'\"}]\n",
    "        )\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        y = model(p.x)\n",
    "        return {\"y_predict\": y.item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfa53971-c6fe-435a-82e7-b1c494e0c217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_models():\n",
    "    print(\"init_models start...\", flush=True)\n",
    "    global model, device\n",
    "    state_dict = load_file(\"models/model.safetensors\")\n",
    "    model = LinearRegression()\n",
    "    model.to(device)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "    print(\"init_models done!\", flush=True)\n",
    "\n",
    "init_models_thread = threading.Thread(target=init_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e32fb0a-17cb-4334-8646-156477c39959",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.get(\"/\")\n",
    "async def index():\n",
    "    global model\n",
    "    if model is None:\n",
    "        return \"Not ready!\"\n",
    "    return \"Hi.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demo_pytorch_ml",
   "language": "python",
   "name": "demo_pytorch_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
